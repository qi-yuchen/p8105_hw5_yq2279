---
title: "p8105_hw5_yq2279"
author: "Qi Yuchen"
date: "2019/11/3"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1

```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

### The function for replacing missing values

```{r}
fill_na = function(x){
  if (is.numeric(x)) {
    x = replace_na(x, mean(x, na.rm = TRUE))
  }
  else if (is.character(x)) {
    x = replace_na(x, "virginica")
  }
  else {
  stop("Not a valid input")
  }
  
  x
}
```

### Apply the function to the columns of iris_with_missing

```{r}
iris_na_filled = map_df(iris_with_missing, fill_na)

knitr::kable(iris_na_filled[1:10,])
```

# Problem 2

### A dataframe containing all file names

```{r}
df_file_name = tibble(
  file_name = list.files("data", full.names = TRUE)
)
```

### Read in data

```{r, message = FALSE}
df_read_data = df_file_name %>% 
  mutate(data = map(file_name, read_csv))
```

### Tidy the result

```{r}
df = df_read_data %>%
  unnest(data) %>% 
  mutate(
    file_name = str_replace(file_name, "data/", ""),
    file_name = str_replace(file_name, "\\.csv", "")
    ) %>% 
  mutate(subject = file_name) %>% 
  separate(file_name, into = c("arm", "ID"), sep = "_") %>% 
  mutate(arm = as.factor(arm)) %>% 
  select(-ID) %>% 
  pivot_longer(week_1:week_8, names_to = "week", names_prefix = "week_" ,values_to = "observation") 
```

### Make a spaghetti plot

```{r}
df %>% 
  ggplot(aes(x = week, y = observation, group = subject, color = arm)) +
  geom_line() +
  labs(
    title = " Observations on each subject over time"
  )
```

There is an increasing trend in the experimental group while in the control group observations there is no obvious trend. The observations from the experimental group are larger than those from the control group after week 6.

# Problem 3

### beta1 = 0

```{r}
# define the function for simulation
sim_regression = function(n = 30, beta0 = 2, beta1, sd = sqrt(50)) {
  
  sim_data = tibble(
    x = rnorm(n),
    y = beta0 + beta1 * x + rnorm(n, 0, sd)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  broom::tidy(ls_fit) %>% 
    filter(term == "x") %>% 
    janitor::clean_names() %>% 
    select(beta1_hat = estimate, p_value)
}

# generate 10000 datasets
sim_results = 
  rerun(10000, sim_regression(beta1 = 0)) %>% 
  bind_rows()

knitr::kable(sim_results[1:10,])
```

### beta1 = 0:6

```{r}
sim_results = 
  tibble(beta1 = c(0:6)) %>% 
  mutate(
    output_lists = map(.x = beta1, ~rerun(10000, sim_regression(beta1 = .x))),
    est_p_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(est_p_dfs)

knitr::kable(sim_results[1:10,])
```

### Make a plot showing the proportion of times the null was rejected

```{r}
# a function to decide rejecting the null or not
h_test = function(p){
  if (p < 0.05) {
    return(1) # 1 means rejecting the null
  } else {
    return(0) # 0 means not rejecting
  }
}

sim_results %>% 
  mutate(reject = map_dbl(p_value, h_test)) %>% 
  group_by(beta1) %>% 
  summarise(proportion_reject = mean(reject)) %>% 
  ggplot(aes(x = beta1, y = proportion_reject)) +
  geom_point() + geom_line() +
  labs(
    title = "Proportion of times the null was rejected",
    y = "proportion"
  )
```

Power increases and tends to 1 as effect size increases.

### Make a plot showing the average estimate of beta1

```{r}
sim_results %>% 
  group_by(beta1) %>% 
  summarise(ave_est = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta1, y = ave_est)) +
  geom_point() + geom_line() +
  labs(
    title = "Average estimate of beta1",
    y = "average estimate"
  )
```

### Only in samples for which the null was rejected

```{r}
df_plot1 = sim_results %>% 
  group_by(beta1) %>% 
  summarise(ave_est = mean(beta1_hat)) %>% 
  mutate(type = "all")

df_plot2 = sim_results %>% 
  mutate(reject = map_dbl(p_value, h_test)) %>%
  filter(reject == 1) %>% 
  group_by(beta1) %>% 
  summarise(ave_est = mean(beta1_hat)) %>% 
  mutate(type = "rejected")

df_plot = bind_rows(df_plot1, df_plot2)
  
df_plot %>% 
  ggplot(aes(x = beta1, y = ave_est, color = type)) +
  geom_point() + geom_line() +
  labs(
    title = "Average estimate of beta1 with all samples and samples where the null was rejected",
    y = "average estimate"
  ) 
```

Generally, the sample average of beta1 across tests for which the null is rejected isn't approximately equal to the true value of bata1. For beta1 = 1:6, the average estimate is larger than the true value and gets closer to the true value as beta1 increases.  
When the null beta1 = 0 is rejected, the beta1 estimate we get is significantly different from 0, so after excluding the estimate values that are more close to zero, the average estimate will be larger for beta1 = 1:6. As beta1 increases, it gets away from the null and power increases, so the average estimate from rejected cases becomes closer to the true beta1.